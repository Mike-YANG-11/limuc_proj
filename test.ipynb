{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\detac\\miniconda3\\envs\\endo_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swattention package not found, loading PyTorch native version of Aggregated Attention\n"
     ]
    }
   ],
   "source": [
    "from models import hiera_tiny_224, transnext_tiny\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from timm.models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.timesformer.timesformer import get_vit_base_patch16_224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token\n",
      "pos_embed\n",
      "time_embed\n",
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "blocks.0.norm1.weight\n",
      "blocks.0.norm1.bias\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.temporal_norm1.weight\n",
      "blocks.0.temporal_norm1.bias\n",
      "blocks.0.temporal_attn.qkv.weight\n",
      "blocks.0.temporal_attn.qkv.bias\n",
      "blocks.0.temporal_attn.proj.weight\n",
      "blocks.0.temporal_attn.proj.bias\n",
      "blocks.0.temporal_fc.weight\n",
      "blocks.0.temporal_fc.bias\n",
      "blocks.0.norm2.weight\n",
      "blocks.0.norm2.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.1.norm1.weight\n",
      "blocks.1.norm1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.temporal_norm1.weight\n",
      "blocks.1.temporal_norm1.bias\n",
      "blocks.1.temporal_attn.qkv.weight\n",
      "blocks.1.temporal_attn.qkv.bias\n",
      "blocks.1.temporal_attn.proj.weight\n",
      "blocks.1.temporal_attn.proj.bias\n",
      "blocks.1.temporal_fc.weight\n",
      "blocks.1.temporal_fc.bias\n",
      "blocks.1.norm2.weight\n",
      "blocks.1.norm2.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.2.norm1.weight\n",
      "blocks.2.norm1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.temporal_norm1.weight\n",
      "blocks.2.temporal_norm1.bias\n",
      "blocks.2.temporal_attn.qkv.weight\n",
      "blocks.2.temporal_attn.qkv.bias\n",
      "blocks.2.temporal_attn.proj.weight\n",
      "blocks.2.temporal_attn.proj.bias\n",
      "blocks.2.temporal_fc.weight\n",
      "blocks.2.temporal_fc.bias\n",
      "blocks.2.norm2.weight\n",
      "blocks.2.norm2.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.3.norm1.weight\n",
      "blocks.3.norm1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.temporal_norm1.weight\n",
      "blocks.3.temporal_norm1.bias\n",
      "blocks.3.temporal_attn.qkv.weight\n",
      "blocks.3.temporal_attn.qkv.bias\n",
      "blocks.3.temporal_attn.proj.weight\n",
      "blocks.3.temporal_attn.proj.bias\n",
      "blocks.3.temporal_fc.weight\n",
      "blocks.3.temporal_fc.bias\n",
      "blocks.3.norm2.weight\n",
      "blocks.3.norm2.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.4.norm1.weight\n",
      "blocks.4.norm1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.temporal_norm1.weight\n",
      "blocks.4.temporal_norm1.bias\n",
      "blocks.4.temporal_attn.qkv.weight\n",
      "blocks.4.temporal_attn.qkv.bias\n",
      "blocks.4.temporal_attn.proj.weight\n",
      "blocks.4.temporal_attn.proj.bias\n",
      "blocks.4.temporal_fc.weight\n",
      "blocks.4.temporal_fc.bias\n",
      "blocks.4.norm2.weight\n",
      "blocks.4.norm2.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.5.norm1.weight\n",
      "blocks.5.norm1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.temporal_norm1.weight\n",
      "blocks.5.temporal_norm1.bias\n",
      "blocks.5.temporal_attn.qkv.weight\n",
      "blocks.5.temporal_attn.qkv.bias\n",
      "blocks.5.temporal_attn.proj.weight\n",
      "blocks.5.temporal_attn.proj.bias\n",
      "blocks.5.temporal_fc.weight\n",
      "blocks.5.temporal_fc.bias\n",
      "blocks.5.norm2.weight\n",
      "blocks.5.norm2.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.6.norm1.weight\n",
      "blocks.6.norm1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.temporal_norm1.weight\n",
      "blocks.6.temporal_norm1.bias\n",
      "blocks.6.temporal_attn.qkv.weight\n",
      "blocks.6.temporal_attn.qkv.bias\n",
      "blocks.6.temporal_attn.proj.weight\n",
      "blocks.6.temporal_attn.proj.bias\n",
      "blocks.6.temporal_fc.weight\n",
      "blocks.6.temporal_fc.bias\n",
      "blocks.6.norm2.weight\n",
      "blocks.6.norm2.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.7.norm1.weight\n",
      "blocks.7.norm1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.temporal_norm1.weight\n",
      "blocks.7.temporal_norm1.bias\n",
      "blocks.7.temporal_attn.qkv.weight\n",
      "blocks.7.temporal_attn.qkv.bias\n",
      "blocks.7.temporal_attn.proj.weight\n",
      "blocks.7.temporal_attn.proj.bias\n",
      "blocks.7.temporal_fc.weight\n",
      "blocks.7.temporal_fc.bias\n",
      "blocks.7.norm2.weight\n",
      "blocks.7.norm2.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.8.norm1.weight\n",
      "blocks.8.norm1.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.temporal_norm1.weight\n",
      "blocks.8.temporal_norm1.bias\n",
      "blocks.8.temporal_attn.qkv.weight\n",
      "blocks.8.temporal_attn.qkv.bias\n",
      "blocks.8.temporal_attn.proj.weight\n",
      "blocks.8.temporal_attn.proj.bias\n",
      "blocks.8.temporal_fc.weight\n",
      "blocks.8.temporal_fc.bias\n",
      "blocks.8.norm2.weight\n",
      "blocks.8.norm2.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.9.norm1.weight\n",
      "blocks.9.norm1.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.temporal_norm1.weight\n",
      "blocks.9.temporal_norm1.bias\n",
      "blocks.9.temporal_attn.qkv.weight\n",
      "blocks.9.temporal_attn.qkv.bias\n",
      "blocks.9.temporal_attn.proj.weight\n",
      "blocks.9.temporal_attn.proj.bias\n",
      "blocks.9.temporal_fc.weight\n",
      "blocks.9.temporal_fc.bias\n",
      "blocks.9.norm2.weight\n",
      "blocks.9.norm2.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.10.norm1.weight\n",
      "blocks.10.norm1.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.temporal_norm1.weight\n",
      "blocks.10.temporal_norm1.bias\n",
      "blocks.10.temporal_attn.qkv.weight\n",
      "blocks.10.temporal_attn.qkv.bias\n",
      "blocks.10.temporal_attn.proj.weight\n",
      "blocks.10.temporal_attn.proj.bias\n",
      "blocks.10.temporal_fc.weight\n",
      "blocks.10.temporal_fc.bias\n",
      "blocks.10.norm2.weight\n",
      "blocks.10.norm2.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.11.norm1.weight\n",
      "blocks.11.norm1.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.temporal_norm1.weight\n",
      "blocks.11.temporal_norm1.bias\n",
      "blocks.11.temporal_attn.qkv.weight\n",
      "blocks.11.temporal_attn.qkv.bias\n",
      "blocks.11.temporal_attn.proj.weight\n",
      "blocks.11.temporal_attn.proj.bias\n",
      "blocks.11.temporal_fc.weight\n",
      "blocks.11.temporal_fc.bias\n",
      "blocks.11.norm2.weight\n",
      "blocks.11.norm2.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.weight\n",
      "head.bias\n"
     ]
    }
   ],
   "source": [
    "model = get_vit_base_patch16_224()\n",
    "for param_name, param in model.named_parameters():\n",
    "    print(param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(4, 3, 224, 224)\n",
    "output = model(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('models/timesformer/pretrain_weights/endo_fm.pth')[\"student\"]\n",
    "\n",
    "# remove keys with prefix \"module.\"\n",
    "new_ckpt = {}\n",
    "for key in ckpt.keys():\n",
    "    new_key = key.replace(\"module.backbone.\", \"\")\n",
    "    if \"head\" not in new_key:\n",
    "        new_ckpt[new_key] = ckpt[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token\n",
      "pos_embed\n",
      "time_embed\n",
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "blocks.0.norm1.weight\n",
      "blocks.0.norm1.bias\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.temporal_norm1.weight\n",
      "blocks.0.temporal_norm1.bias\n",
      "blocks.0.temporal_attn.qkv.weight\n",
      "blocks.0.temporal_attn.qkv.bias\n",
      "blocks.0.temporal_attn.proj.weight\n",
      "blocks.0.temporal_attn.proj.bias\n",
      "blocks.0.temporal_fc.weight\n",
      "blocks.0.temporal_fc.bias\n",
      "blocks.0.norm2.weight\n",
      "blocks.0.norm2.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.1.norm1.weight\n",
      "blocks.1.norm1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.temporal_norm1.weight\n",
      "blocks.1.temporal_norm1.bias\n",
      "blocks.1.temporal_attn.qkv.weight\n",
      "blocks.1.temporal_attn.qkv.bias\n",
      "blocks.1.temporal_attn.proj.weight\n",
      "blocks.1.temporal_attn.proj.bias\n",
      "blocks.1.temporal_fc.weight\n",
      "blocks.1.temporal_fc.bias\n",
      "blocks.1.norm2.weight\n",
      "blocks.1.norm2.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.2.norm1.weight\n",
      "blocks.2.norm1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.temporal_norm1.weight\n",
      "blocks.2.temporal_norm1.bias\n",
      "blocks.2.temporal_attn.qkv.weight\n",
      "blocks.2.temporal_attn.qkv.bias\n",
      "blocks.2.temporal_attn.proj.weight\n",
      "blocks.2.temporal_attn.proj.bias\n",
      "blocks.2.temporal_fc.weight\n",
      "blocks.2.temporal_fc.bias\n",
      "blocks.2.norm2.weight\n",
      "blocks.2.norm2.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.3.norm1.weight\n",
      "blocks.3.norm1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.temporal_norm1.weight\n",
      "blocks.3.temporal_norm1.bias\n",
      "blocks.3.temporal_attn.qkv.weight\n",
      "blocks.3.temporal_attn.qkv.bias\n",
      "blocks.3.temporal_attn.proj.weight\n",
      "blocks.3.temporal_attn.proj.bias\n",
      "blocks.3.temporal_fc.weight\n",
      "blocks.3.temporal_fc.bias\n",
      "blocks.3.norm2.weight\n",
      "blocks.3.norm2.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.4.norm1.weight\n",
      "blocks.4.norm1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.temporal_norm1.weight\n",
      "blocks.4.temporal_norm1.bias\n",
      "blocks.4.temporal_attn.qkv.weight\n",
      "blocks.4.temporal_attn.qkv.bias\n",
      "blocks.4.temporal_attn.proj.weight\n",
      "blocks.4.temporal_attn.proj.bias\n",
      "blocks.4.temporal_fc.weight\n",
      "blocks.4.temporal_fc.bias\n",
      "blocks.4.norm2.weight\n",
      "blocks.4.norm2.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.5.norm1.weight\n",
      "blocks.5.norm1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.temporal_norm1.weight\n",
      "blocks.5.temporal_norm1.bias\n",
      "blocks.5.temporal_attn.qkv.weight\n",
      "blocks.5.temporal_attn.qkv.bias\n",
      "blocks.5.temporal_attn.proj.weight\n",
      "blocks.5.temporal_attn.proj.bias\n",
      "blocks.5.temporal_fc.weight\n",
      "blocks.5.temporal_fc.bias\n",
      "blocks.5.norm2.weight\n",
      "blocks.5.norm2.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.6.norm1.weight\n",
      "blocks.6.norm1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.temporal_norm1.weight\n",
      "blocks.6.temporal_norm1.bias\n",
      "blocks.6.temporal_attn.qkv.weight\n",
      "blocks.6.temporal_attn.qkv.bias\n",
      "blocks.6.temporal_attn.proj.weight\n",
      "blocks.6.temporal_attn.proj.bias\n",
      "blocks.6.temporal_fc.weight\n",
      "blocks.6.temporal_fc.bias\n",
      "blocks.6.norm2.weight\n",
      "blocks.6.norm2.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.7.norm1.weight\n",
      "blocks.7.norm1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.temporal_norm1.weight\n",
      "blocks.7.temporal_norm1.bias\n",
      "blocks.7.temporal_attn.qkv.weight\n",
      "blocks.7.temporal_attn.qkv.bias\n",
      "blocks.7.temporal_attn.proj.weight\n",
      "blocks.7.temporal_attn.proj.bias\n",
      "blocks.7.temporal_fc.weight\n",
      "blocks.7.temporal_fc.bias\n",
      "blocks.7.norm2.weight\n",
      "blocks.7.norm2.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.8.norm1.weight\n",
      "blocks.8.norm1.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.temporal_norm1.weight\n",
      "blocks.8.temporal_norm1.bias\n",
      "blocks.8.temporal_attn.qkv.weight\n",
      "blocks.8.temporal_attn.qkv.bias\n",
      "blocks.8.temporal_attn.proj.weight\n",
      "blocks.8.temporal_attn.proj.bias\n",
      "blocks.8.temporal_fc.weight\n",
      "blocks.8.temporal_fc.bias\n",
      "blocks.8.norm2.weight\n",
      "blocks.8.norm2.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.9.norm1.weight\n",
      "blocks.9.norm1.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.temporal_norm1.weight\n",
      "blocks.9.temporal_norm1.bias\n",
      "blocks.9.temporal_attn.qkv.weight\n",
      "blocks.9.temporal_attn.qkv.bias\n",
      "blocks.9.temporal_attn.proj.weight\n",
      "blocks.9.temporal_attn.proj.bias\n",
      "blocks.9.temporal_fc.weight\n",
      "blocks.9.temporal_fc.bias\n",
      "blocks.9.norm2.weight\n",
      "blocks.9.norm2.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.10.norm1.weight\n",
      "blocks.10.norm1.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.temporal_norm1.weight\n",
      "blocks.10.temporal_norm1.bias\n",
      "blocks.10.temporal_attn.qkv.weight\n",
      "blocks.10.temporal_attn.qkv.bias\n",
      "blocks.10.temporal_attn.proj.weight\n",
      "blocks.10.temporal_attn.proj.bias\n",
      "blocks.10.temporal_fc.weight\n",
      "blocks.10.temporal_fc.bias\n",
      "blocks.10.norm2.weight\n",
      "blocks.10.norm2.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.11.norm1.weight\n",
      "blocks.11.norm1.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.temporal_norm1.weight\n",
      "blocks.11.temporal_norm1.bias\n",
      "blocks.11.temporal_attn.qkv.weight\n",
      "blocks.11.temporal_attn.qkv.bias\n",
      "blocks.11.temporal_attn.proj.weight\n",
      "blocks.11.temporal_attn.proj.bias\n",
      "blocks.11.temporal_fc.weight\n",
      "blocks.11.temporal_fc.bias\n",
      "blocks.11.norm2.weight\n",
      "blocks.11.norm2.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n"
     ]
    }
   ],
   "source": [
    "for key in new_ckpt.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_ckpt, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_small = create_model('vit_small_patch16_224', num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token\n",
      "pos_embed\n",
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "blocks.0.norm1.weight\n",
      "blocks.0.norm1.bias\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.norm2.weight\n",
      "blocks.0.norm2.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.1.norm1.weight\n",
      "blocks.1.norm1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.norm2.weight\n",
      "blocks.1.norm2.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.2.norm1.weight\n",
      "blocks.2.norm1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.norm2.weight\n",
      "blocks.2.norm2.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.3.norm1.weight\n",
      "blocks.3.norm1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.norm2.weight\n",
      "blocks.3.norm2.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.4.norm1.weight\n",
      "blocks.4.norm1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.norm2.weight\n",
      "blocks.4.norm2.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.5.norm1.weight\n",
      "blocks.5.norm1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.norm2.weight\n",
      "blocks.5.norm2.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.6.norm1.weight\n",
      "blocks.6.norm1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.norm2.weight\n",
      "blocks.6.norm2.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.7.norm1.weight\n",
      "blocks.7.norm1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.norm2.weight\n",
      "blocks.7.norm2.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.8.norm1.weight\n",
      "blocks.8.norm1.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.norm2.weight\n",
      "blocks.8.norm2.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.9.norm1.weight\n",
      "blocks.9.norm1.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.norm2.weight\n",
      "blocks.9.norm2.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.10.norm1.weight\n",
      "blocks.10.norm1.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.norm2.weight\n",
      "blocks.10.norm2.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.11.norm1.weight\n",
      "blocks.11.norm1.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.norm2.weight\n",
      "blocks.11.norm2.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.weight\n",
      "head.bias\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in vit_small.named_parameters():\n",
    "    print(param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token\n",
      "pos_embed\n",
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "blocks.0.norm1.weight\n",
      "blocks.0.norm1.bias\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.norm2.weight\n",
      "blocks.0.norm2.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.1.norm1.weight\n",
      "blocks.1.norm1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.norm2.weight\n",
      "blocks.1.norm2.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.2.norm1.weight\n",
      "blocks.2.norm1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.norm2.weight\n",
      "blocks.2.norm2.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.3.norm1.weight\n",
      "blocks.3.norm1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.norm2.weight\n",
      "blocks.3.norm2.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.4.norm1.weight\n",
      "blocks.4.norm1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.norm2.weight\n",
      "blocks.4.norm2.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.5.norm1.weight\n",
      "blocks.5.norm1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.norm2.weight\n",
      "blocks.5.norm2.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.6.norm1.weight\n",
      "blocks.6.norm1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.norm2.weight\n",
      "blocks.6.norm2.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.7.norm1.weight\n",
      "blocks.7.norm1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.norm2.weight\n",
      "blocks.7.norm2.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.8.norm1.weight\n",
      "blocks.8.norm1.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.norm2.weight\n",
      "blocks.8.norm2.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.9.norm1.weight\n",
      "blocks.9.norm1.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.norm2.weight\n",
      "blocks.9.norm2.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.10.norm1.weight\n",
      "blocks.10.norm1.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.norm2.weight\n",
      "blocks.10.norm2.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.11.norm1.weight\n",
      "blocks.11.norm1.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.norm2.weight\n",
      "blocks.11.norm2.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"./pretrain_weights/VITS_GastroNet-5M_DINOv1.pth\")\n",
    "for k in list(ckpt.keys()):\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hiera_tiny_224()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.lr_decay as lrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter groups: \n",
      "{\n",
      "  \"layer_0_no_decay\": {\n",
      "    \"lr_scale\": 0.023757264018058777,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"pos_embed\",\n",
      "      \"patch_embed.proj.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_0_decay\": {\n",
      "    \"lr_scale\": 0.023757264018058777,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"patch_embed.proj.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_1_no_decay\": {\n",
      "    \"lr_scale\": 0.03167635202407837,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.0.norm1.weight\",\n",
      "      \"blocks.0.norm1.bias\",\n",
      "      \"blocks.0.attn.qkv.bias\",\n",
      "      \"blocks.0.attn.proj.bias\",\n",
      "      \"blocks.0.norm2.weight\",\n",
      "      \"blocks.0.norm2.bias\",\n",
      "      \"blocks.0.mlp.fc1.bias\",\n",
      "      \"blocks.0.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_1_decay\": {\n",
      "    \"lr_scale\": 0.03167635202407837,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.0.attn.qkv.weight\",\n",
      "      \"blocks.0.attn.proj.weight\",\n",
      "      \"blocks.0.mlp.fc1.weight\",\n",
      "      \"blocks.0.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_2_no_decay\": {\n",
      "    \"lr_scale\": 0.04223513603210449,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.1.norm1.weight\",\n",
      "      \"blocks.1.norm1.bias\",\n",
      "      \"blocks.1.attn.qkv.bias\",\n",
      "      \"blocks.1.attn.proj.bias\",\n",
      "      \"blocks.1.norm2.weight\",\n",
      "      \"blocks.1.norm2.bias\",\n",
      "      \"blocks.1.mlp.fc1.bias\",\n",
      "      \"blocks.1.mlp.fc2.bias\",\n",
      "      \"blocks.1.proj.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_2_decay\": {\n",
      "    \"lr_scale\": 0.04223513603210449,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.1.attn.qkv.weight\",\n",
      "      \"blocks.1.attn.proj.weight\",\n",
      "      \"blocks.1.mlp.fc1.weight\",\n",
      "      \"blocks.1.mlp.fc2.weight\",\n",
      "      \"blocks.1.proj.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_3_no_decay\": {\n",
      "    \"lr_scale\": 0.056313514709472656,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.2.norm1.weight\",\n",
      "      \"blocks.2.norm1.bias\",\n",
      "      \"blocks.2.attn.qkv.bias\",\n",
      "      \"blocks.2.attn.proj.bias\",\n",
      "      \"blocks.2.norm2.weight\",\n",
      "      \"blocks.2.norm2.bias\",\n",
      "      \"blocks.2.mlp.fc1.bias\",\n",
      "      \"blocks.2.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_3_decay\": {\n",
      "    \"lr_scale\": 0.056313514709472656,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.2.attn.qkv.weight\",\n",
      "      \"blocks.2.attn.proj.weight\",\n",
      "      \"blocks.2.mlp.fc1.weight\",\n",
      "      \"blocks.2.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_4_no_decay\": {\n",
      "    \"lr_scale\": 0.07508468627929688,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.3.norm1.weight\",\n",
      "      \"blocks.3.norm1.bias\",\n",
      "      \"blocks.3.attn.qkv.bias\",\n",
      "      \"blocks.3.attn.proj.bias\",\n",
      "      \"blocks.3.norm2.weight\",\n",
      "      \"blocks.3.norm2.bias\",\n",
      "      \"blocks.3.mlp.fc1.bias\",\n",
      "      \"blocks.3.mlp.fc2.bias\",\n",
      "      \"blocks.3.proj.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_4_decay\": {\n",
      "    \"lr_scale\": 0.07508468627929688,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.3.attn.qkv.weight\",\n",
      "      \"blocks.3.attn.proj.weight\",\n",
      "      \"blocks.3.mlp.fc1.weight\",\n",
      "      \"blocks.3.mlp.fc2.weight\",\n",
      "      \"blocks.3.proj.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_5_no_decay\": {\n",
      "    \"lr_scale\": 0.1001129150390625,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.4.norm1.weight\",\n",
      "      \"blocks.4.norm1.bias\",\n",
      "      \"blocks.4.attn.qkv.bias\",\n",
      "      \"blocks.4.attn.proj.bias\",\n",
      "      \"blocks.4.norm2.weight\",\n",
      "      \"blocks.4.norm2.bias\",\n",
      "      \"blocks.4.mlp.fc1.bias\",\n",
      "      \"blocks.4.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_5_decay\": {\n",
      "    \"lr_scale\": 0.1001129150390625,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.4.attn.qkv.weight\",\n",
      "      \"blocks.4.attn.proj.weight\",\n",
      "      \"blocks.4.mlp.fc1.weight\",\n",
      "      \"blocks.4.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_6_no_decay\": {\n",
      "    \"lr_scale\": 0.13348388671875,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.5.norm1.weight\",\n",
      "      \"blocks.5.norm1.bias\",\n",
      "      \"blocks.5.attn.qkv.bias\",\n",
      "      \"blocks.5.attn.proj.bias\",\n",
      "      \"blocks.5.norm2.weight\",\n",
      "      \"blocks.5.norm2.bias\",\n",
      "      \"blocks.5.mlp.fc1.bias\",\n",
      "      \"blocks.5.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_6_decay\": {\n",
      "    \"lr_scale\": 0.13348388671875,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.5.attn.qkv.weight\",\n",
      "      \"blocks.5.attn.proj.weight\",\n",
      "      \"blocks.5.mlp.fc1.weight\",\n",
      "      \"blocks.5.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_7_no_decay\": {\n",
      "    \"lr_scale\": 0.177978515625,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.6.norm1.weight\",\n",
      "      \"blocks.6.norm1.bias\",\n",
      "      \"blocks.6.attn.qkv.bias\",\n",
      "      \"blocks.6.attn.proj.bias\",\n",
      "      \"blocks.6.norm2.weight\",\n",
      "      \"blocks.6.norm2.bias\",\n",
      "      \"blocks.6.mlp.fc1.bias\",\n",
      "      \"blocks.6.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_7_decay\": {\n",
      "    \"lr_scale\": 0.177978515625,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.6.attn.qkv.weight\",\n",
      "      \"blocks.6.attn.proj.weight\",\n",
      "      \"blocks.6.mlp.fc1.weight\",\n",
      "      \"blocks.6.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_8_no_decay\": {\n",
      "    \"lr_scale\": 0.2373046875,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.7.norm1.weight\",\n",
      "      \"blocks.7.norm1.bias\",\n",
      "      \"blocks.7.attn.qkv.bias\",\n",
      "      \"blocks.7.attn.proj.bias\",\n",
      "      \"blocks.7.norm2.weight\",\n",
      "      \"blocks.7.norm2.bias\",\n",
      "      \"blocks.7.mlp.fc1.bias\",\n",
      "      \"blocks.7.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_8_decay\": {\n",
      "    \"lr_scale\": 0.2373046875,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.7.attn.qkv.weight\",\n",
      "      \"blocks.7.attn.proj.weight\",\n",
      "      \"blocks.7.mlp.fc1.weight\",\n",
      "      \"blocks.7.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_9_no_decay\": {\n",
      "    \"lr_scale\": 0.31640625,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.8.norm1.weight\",\n",
      "      \"blocks.8.norm1.bias\",\n",
      "      \"blocks.8.attn.qkv.bias\",\n",
      "      \"blocks.8.attn.proj.bias\",\n",
      "      \"blocks.8.norm2.weight\",\n",
      "      \"blocks.8.norm2.bias\",\n",
      "      \"blocks.8.mlp.fc1.bias\",\n",
      "      \"blocks.8.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_9_decay\": {\n",
      "    \"lr_scale\": 0.31640625,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.8.attn.qkv.weight\",\n",
      "      \"blocks.8.attn.proj.weight\",\n",
      "      \"blocks.8.mlp.fc1.weight\",\n",
      "      \"blocks.8.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_10_no_decay\": {\n",
      "    \"lr_scale\": 0.421875,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.9.norm1.weight\",\n",
      "      \"blocks.9.norm1.bias\",\n",
      "      \"blocks.9.attn.qkv.bias\",\n",
      "      \"blocks.9.attn.proj.bias\",\n",
      "      \"blocks.9.norm2.weight\",\n",
      "      \"blocks.9.norm2.bias\",\n",
      "      \"blocks.9.mlp.fc1.bias\",\n",
      "      \"blocks.9.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_10_decay\": {\n",
      "    \"lr_scale\": 0.421875,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.9.attn.qkv.weight\",\n",
      "      \"blocks.9.attn.proj.weight\",\n",
      "      \"blocks.9.mlp.fc1.weight\",\n",
      "      \"blocks.9.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_11_no_decay\": {\n",
      "    \"lr_scale\": 0.5625,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.10.norm1.weight\",\n",
      "      \"blocks.10.norm1.bias\",\n",
      "      \"blocks.10.attn.qkv.bias\",\n",
      "      \"blocks.10.attn.proj.bias\",\n",
      "      \"blocks.10.norm2.weight\",\n",
      "      \"blocks.10.norm2.bias\",\n",
      "      \"blocks.10.mlp.fc1.bias\",\n",
      "      \"blocks.10.mlp.fc2.bias\",\n",
      "      \"blocks.10.proj.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_11_decay\": {\n",
      "    \"lr_scale\": 0.5625,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.10.attn.qkv.weight\",\n",
      "      \"blocks.10.attn.proj.weight\",\n",
      "      \"blocks.10.mlp.fc1.weight\",\n",
      "      \"blocks.10.mlp.fc2.weight\",\n",
      "      \"blocks.10.proj.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_12_no_decay\": {\n",
      "    \"lr_scale\": 0.75,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"blocks.11.norm1.weight\",\n",
      "      \"blocks.11.norm1.bias\",\n",
      "      \"blocks.11.attn.qkv.bias\",\n",
      "      \"blocks.11.attn.proj.bias\",\n",
      "      \"blocks.11.norm2.weight\",\n",
      "      \"blocks.11.norm2.bias\",\n",
      "      \"blocks.11.mlp.fc1.bias\",\n",
      "      \"blocks.11.mlp.fc2.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_12_decay\": {\n",
      "    \"lr_scale\": 0.75,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"blocks.11.attn.qkv.weight\",\n",
      "      \"blocks.11.attn.proj.weight\",\n",
      "      \"blocks.11.mlp.fc1.weight\",\n",
      "      \"blocks.11.mlp.fc2.weight\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_13_no_decay\": {\n",
      "    \"lr_scale\": 1.0,\n",
      "    \"weight_decay\": 0.0,\n",
      "    \"params\": [\n",
      "      \"norm.weight\",\n",
      "      \"norm.bias\",\n",
      "      \"head.projection.bias\"\n",
      "    ]\n",
      "  },\n",
      "  \"layer_13_decay\": {\n",
      "    \"lr_scale\": 1.0,\n",
      "    \"weight_decay\": 0.05,\n",
      "    \"params\": [\n",
      "      \"head.projection.weight\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "param_groups = lrd.param_groups_lrd(model, weight_decay=0.05, no_weight_decay_list=model.no_weight_decay(), layer_decay=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000])\n",
      "tensor(0.0018, grad_fn=<MaxBackward1>) tensor(-0.0015, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(4, 3, 224, 224)\n",
    "output = model(input)\n",
    "print(output.size())\n",
    "print(torch.max(output), torch.min(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "endo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
